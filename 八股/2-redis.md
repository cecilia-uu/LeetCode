# 1. 使用场景
1. 你在最近的项目中的那些场景中使用了redis？
（目的）验证项目场景真实性，切入点
- 根据自己简历上的业务进行回答
- 缓存
- 分布式锁

## 缓存
### 穿透、击穿、雪崩
2. 如果发生了缓存穿透，该如何解决？
- 缓存穿透：查询一个不存在的数据，mysql因为一直查不到数据所以不会直接写入缓存中，就会导致每次请求都查数据库。一般来源于恶意攻击！
- 解决方案1：缓存空数据，查询返回的数据为空时，仍把这个空结果进行缓存。如 {key:1, value: null}
优点：简单
缺点：消耗内存，可能会发生不一致的问题
- 解决方案2: 加入boolean过滤器
优点：内存占用少，没有多余的key
缺点：实现复杂，存在误判

- 布隆过滤器（BloomFilter）：
bitmap(位图)：相当于是一个以bit位为单位的数组，数组中每个单元只能存储二进制数0/1
作用：用于检索一个元素是否在一个集合中
误判率：数组越小，误判率越大；数组越大，误判率越小，但是带来了更多的内存消耗。
实现方案：Redisson/Guava

3. 击穿
给某一个key设置了过期时间，当key过期时，恰好这个时间点，对这个key有了大量的并发请求，有可能会压垮DB。
- 解决方案1: 互斥锁
强一致性, 性能差
- 解决方案2: 逻辑过期
高可用，性能优, 不能保证数据绝对一致。

todo: 具体是啥样的？？？？

4. 雪崩
同一时间段，大量的缓存key同时失效/redis服务宕机，导致大量请求到达数据库，带来巨大压力。
解决方案：
- 给不同key的TTL添加随机值
- 利用redis集群提高服务的可用性。哨兵模式、集群模式
- 给缓存业务添加降级限流策略。ngxin/spring cloud gateway
降级可以作为系统的保底策略，适用于穿透、击穿、雪崩
- 给业务添加多级缓存 Guava/Caffeine

* 总结
穿透无中生有key,布隆过滤null隔离。
缓存击穿过期key,锁与非期解难题。
雪崩大量过期key,过期时间要随机。
面试必考三兄弟，可用限流来保底。

### 双写一致、持久化
5. redis作为缓存，mysql的数据如何与redis进行同步呢？（双写一致性）
* 定义：双写一致性：当修改了数据库的数据时同时也要更新缓存的数据，两者数据要一致。
1) 一定要设置前提，介绍自己的业务背景 （一致性要求高/允许延迟一致）
2) 两种答题方向
2.1 异步的方案
- 允许延时一致性的业务，采用异步通知
* 使用MQ中间件，更新数据后，通知缓存删除
* 利用Canal的异步通知，不需要修改业务代码，伪装为mysql的一个从节点，canal通过读取binlog数据更新缓存。（基于Canal的异步通知：监听mysql的binlog（二进制日志记录了所有DDL数据定义语言语句和DML数据操纵语言语句，但不包括数据查询语句））
* 异步通知保证数据的最终一致性。

2.2 强一致性，采用redisson提供的读写锁
- 共享锁：读锁readLock，加锁后，其他线程可以共享读操作
- 排他锁/独占锁：writeLock，加锁后，阻塞其他线程读写操作
- 强一致/性能低

3) 读操作：缓存命中，直接返回；未命中，继续查询DB，写入缓存，设置过期时间
4) 写操作：延迟双删
删除缓存 -> 修改数据库 -> （延迟） 删除缓存

6. 数据的持久化怎么做的？
1） RDB
全称redis database backup file（redis数据备份文件），也叫Redis数据快照。简单来说，就是把内存中的所有数据都记录到磁盘。当redis实例故障重启后，从磁盘读取快照文件，恢复数据。
```bash
save # 由redis主进程执行，会阻塞所有命令
bgsave # 开启子进程执行RDB，避免主进程受影响
```
* 执行原理？
bgsave开始的时候会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件。
fork采用的是copy-on-write技术：
当主进程执行读操作的时候，访问共享内存
当主进程执行写操作的时候，会拷贝一份数据，执行写操作。

2）AOF
全称是Append Only File （追加文件）。redis处理的每一个写命令都会记录在AOF文件，可以看作是命令日志文件。
因为是记录命令，AOF文件比RDB文件大很多。而且AOF会对同一key进行多次写操作，但是只有最后一次写操作才有意义。通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少命令达到相同效果。

### 数据过期、淘汰策略
7. redis的key过期后，会立即删除吗？
* 惰性删除：设置该key过期时间后，我们不再管，当需要该key时，再检查是否过期。
优点：对CPU友好，只会在需要该key的时候才会检查
缺点：对内存不友好，如果一个key已经过期了，但是一直没用，会一直存在内存里，不释放
* 定期删除：每隔一段时间，我们就对一些key进行检查，删除里面过期的key （从一定数量的数据库中取出一定数量的随机key进行检查，并删除其中的过期key）
两种模式：
1）SLOW：定时任务，执行频率默认为10hz，每次不超过25ms，以通过修改配置文件redis.conf的hz选项调整这个次数
2）FAST：频率不固定，但是两次间隔不低于2ms,每次耗时不超过1ms
优点：可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响。定期删除也能有效释放过期键占用的内存。
缺点：难以确定删除操作的执行时长和频率
* 两个都用

8. 缓存过多时候怎么办？
* 数据的淘汰策略：当redis的内存不够用的时候，此时向redis添加新的key，那么它就会以某一规则将内存中的数据删除，这种数据的删除规则被称为内存的淘汰策略。
* 8种策略：
- noeviction: 不淘汰任何key，但是内存满的时候不允许写入新数据，这是默认设置。
- volatile-ttl: 对设置了TTL的key，比较key的剩余TTL值，越小越先被淘汰。
- allkeys-random: 对全体key,随机淘汰
- volatile-random: 对设置了TTL的key，随机淘汰
- allkeys-lru: 对全体key，基于LRU算法进行淘汰
- volatile-lru: 对设置了TTL的key，基于LRU算法进行淘汰
- allkeys-lfu: 对全体key，基于LFU算法进行淘汰
- volatile-lfu: 对设置了TTL的key，基于LFU算法进行淘汰

* 使用建议
1. 优先使用allkeys-lru策略。充分利用LRU算法的优势，把最近最常访问的数据留在缓存中。如果业务有明显的冷热区分，建议使用。
2. 如果业务中数据访问频率不大，没有明显冷热数据区分，建议使用allkeys-random。
3. 如果业务中有置顶需求，可以使用volatile-lru策略，同时置顶数据不设置过期时间，这些数据就可以不被删除。
4. 如果业务中有短时高频访问的数据，可以使用allkeys-lfu/volatile-lfu。

* 其他问题
1. 数据库中有1000万数据，redis只能缓存20万数据，如何保证redis中都是热点数据？
使用allkeys-lru，留下来的都是经常访问的热点数据。
2. redis中的内存用完会发生什么？
主要看淘汰策略是啥？如果是默认配置，会直接报错。

## 分布式锁
9. redis分布式锁是如何实现的？
* 先按照简历上的业务进行描述使用的场景
* 我们使用的是Redisson实现的分布式锁，底层是setnx和lua脚本（保证原子性）

使用场景：集群情况下的定时任务、抢单、幂等性场景
实现分布式锁住要利用redis的setnx命令。setnx是set if not exists的缩写
- 获取锁：
```bash
SET lock value NX EX 10 # 添加锁。NX是互斥，EX是设置超时时间
```
- 释放锁：
```bash
DEL key # 删掉
```
10. 如何合理的控制锁的有效时长？
Redisson提供的分布式锁中，有一个watch dog，一个线程获取锁成功以后，它会给持有锁的线程续期（默认是每隔10秒续期一次）

11. redisson的锁可以重入吗？
可重入。多个锁重入需要判断是否是当前线程，是利用hash结构记录线程id和重入次数来进行存储。
{lock_name: [thread_id, cnt_of_re-enter]}

加锁、设置过期时间等操作都是基于lua脚本完成

12. 锁能解决主从一致性问题吗？
不能，但是可以使用redisson提供的红锁解决，但是这样性能太低了。如果非要保证数据的强一致性，建议使用zookeeper实现分布式锁。

RedLock（红锁）：不能只在一个redis实例中创建锁，得在n/2+1个实例上加锁。
- trade-off: 性能差+实现复杂+运维繁琐

AP思想 - redis
CP思想 - zookeeper

### setnx\redisson
## 计数器

## 保存token
## 消息队列
## 延迟队列

# 2. 其他面试问题
## 集群
13. redis中提供的集群方案？
- 主从复制 {
    1. 简介：单节点redis的并发能力是有上限的，要进一步提高redis的并发能力，需要搭建主从集群，实现读写分离。
    一般都是一主多从，主节点负责写数据，从节点负责读数据。

    2. 原理/流程 {
        2.1 主从全量同步 {
            * replication id: 简称replid，是数据集的标记，id一致说明是同一数据集。每一个master都有唯一的replid，slave会继承master节点的replid
            * offset：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset说明slave数据落后于master，需要更新。（git的原理是不是一样？）
            (1) 从节点请求主节点同步数据 (replication id, offset)
            (2) 主节点判断是否是第一次请求，是就与从节点同步版本信息 (replication id, offset)
            (3) 主节点执行bgsave，生成rdb文件后，发送给从节点执行
            (4) 在rdb生成执行期间，主节点会以命令的方式记录到缓冲区（一个日志文件）
            (5) 把生成后的命令日志文件发送到从节点进行同步
        }

        2.2 主从增量同步(slave重启或后期数据变化) {
            (1) 从节点请求主节点同步数据, 主节点判断是否是第一次请求，不是就获取从节点的offset值
            (2) 主节点从命令日志中获取offset值后的数据，发送给从节点进行数据同步
        }
    }
    
}

- 哨兵模式 {
    * redis提供了哨兵(sentinel)机制来实现主从集群的自动故障恢复。
    * 监控：sentinel会不断检查我们的master和slave是否按照预期工作。
    * 自动故障恢复：如果master故障，sentinel会将一个slave提升为master。如果故障实例恢复后也以新的master为主。
    * 通知：sentinel充当redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给redis的客户端。
    服务状态监控 {
        sentinel基于心脏机制检测服务状态，每隔1秒向集群的每个实例发送ping命令：
        * 主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。
        * 客观下线：若超过指定数量(quorum)的sentinel都认为该实例主观下线，则该实例客观下线。quorum值最好超过sentinel实例数量的一半。
    }
    哨兵选主规则 {
        * 首先判断主从节点断开时间的长短，如超过指定值就排除该从节点
        * 然后判断从节点的slave-priority值，越小优先级越高
        * 如果一样，则判断slave节点的offset值，越大优先级越高
        * 最后判断slave节点的运行id大小，越小优先级越高
    }
    redis集群脑裂
}

- 分片集群 {
    * 海量数据存储问题
    * 高并发写的问题
    使用分片集群可以解决上述问题，分片集群特征： {
        * 集群中有多个master，每个master保存不同数据
        * 每个master都可以有多个salve节点
        * master之间通过ping检测彼此的健康状态
        * 客户端请求可以访问集群任意节点，最终都会被转发到正确节点
    }
    数据读写
    redis分片集群引入了哈希槽的概念，redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分的hash槽。
}

14. redis主从数据同步的流程是什么？

15. 怎么保证redis的高并发高可用？
哨兵模式：实现主从集群的自动故障恢复（监控、自动故障恢复、通知）

16. 你们使用redis是单点还是集群，哪种集群？
主从（1主1从）+哨兵。单节点不超过10G内存，如果redis内存不足则可以向不同服务分配独立的redis主从节点。

17. redis分片集群有什么作用？
1）集群中有多个master，每个master保存不同数据
2）每个master都可以有多个slave节点
3）master之间通过ping检测彼此健康状况
4）客户端请求可以访问集群任意节点，最终都会被转发到正确节点

18. redis分片集群中数据是怎么存储和读取的？
1）redis分片集群引入了哈希槽的概念，redis集群有16384个哈希槽
2）将16384个插槽分配到不同的实例
3）读写数据：根据key的有效部分计算哈希值，对16384取余（有效部分，如果key前面有大括号，大括号的内容就是有效部分，如果没有，则以key本身作为有效部分），余数作为插槽，寻找插槽所在的实例。

19. redis集群脑裂，怎么解决？
集群脑裂是由于主节点和sentinel处于不同的网络分区，使得sentinel没有能够心跳感知到主节点，所以通过选举的方式提升了一个从节点为主，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在老的主节点那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会将老的主节点降为从节点，这时再从新的master同步数据，会导致数据丢失。

解决：我们可以修改redis的配置，可以设置最少的从节点数量以及缩短主从数据同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失。

## 事务
## redis是单线程的，为什么那么快？
1）redis是纯内存操作，C语言编写
2）采用单线程，避免不必要的上下文切换可竞争条件，多线程还要考虑线程安全问题
3）使用I/O多路复用模型，非阻塞IO

能解释一下I/O多路复用模型？
redis是纯内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，I/O多路复用模型主要就是实现了高效的网络请求。
1）用户空间和内核空间 {
    * linux系统中一个进程使用的内存情况划分为两个部分：内核空间、用户空间
    * 用户空间只能执行受限的命令（Ring3），而且不能直接调用系统资源，必须通过内核提供的接口进行访问
    * 内核空间可以执行特权命令（Ring0），调用一切系统资源
    
    Linux系统为了提高IO效率，会在用户空间和内核空间都加入缓冲区：
    * 写数据时，要把用户缓冲数据拷贝到内核缓冲区，然后写入设备
    * 读数据时，要把设备读取数据到内核缓冲区，然后拷贝到用户缓冲区
}
2）常见的IO模型
2.1 阻塞IO(Blocking IO) {
    两个阶段都需要阻塞等待

    阶段1:
    用户进程尝试读取数据（比如网卡数据） -> 此时数据尚未到达，内核需要等待数据 -> 此时用户进程也处于阻塞状态

    阶段2：
    数据到达并拷贝到内存缓冲区，表示已就绪 -> 将内核数据拷贝到用户缓冲区 -> 拷贝过程中，用户进程依然阻塞等待 -> 拷贝完成，用户进程解除阻塞，处理数据

}
2.2 非阻塞IO(Nonblocking IO) {
    非阻塞IO的recvfrom操作会立刻返回结果而不是阻塞用户进程。

    阶段1:
    用户进程尝试读取数据（比如网卡数据） -> 此时数据尚未到达，内核需要等待数据 -> 返回异常给用户进程 -> 用户进程拿到error后，再次尝试读取 -> 循环往复，直到数据就绪

    阶段2:
    将内核数据拷贝到用户缓冲区 -> 拷贝过程中，用户进程依然阻塞等待 -> 拷贝完成，用户进程解除阻塞，处理数据

    非阻塞IO模型中，用户进程在第一阶段是非阻塞的，第二阶段是阻塞状态。虽然是非阻塞，但是性能并没有得到提高。而且忙等机制会导致CPU空转，CPU使用率暴增。
}
2.3 IO多路复用(IO multiplexing) {
    利用单个线程来同时监听多个socket，并在某个socket可读、可写时候得到通知，从而避免无效的等待，充分利用CPU资源。

    阶段1:
    用户进程调用select，指定要监听的socket集合 -> 内核监听对应的多个socket -> 任意一个/多个socket数据就绪则返回readable -> 过程中用户进程阻塞

    阶段2:
    用户进程找到就绪的socket -> 依次调用recvfrom读取数据 -> 内核将数据拷贝到用户空间 -> 用户进程处理数据

    监听/通知socket的方式有多种：
    * select
    * poll
    * epoll 

    差异：
    * select和poll只会通知用户进程有socket就绪，但不确定是哪个socket，需要用户进程逐个遍历socket来确认
    * epoll则会在通知用户进程socket就绪的同时，把已就绪的socket写入用户空间
}

3）redis网络模型
redis通过IO多路复用来提高网络性能，并且支持多种不同的多路复用实现，并且将这些实现进行封装，提供了统一的高性能事件库。
* 连接应答处理器
* 命令回复处理器，在redis 6.0之后，为了提升更好的性能，使用了多线程来处理回复事件
* 命令请求处理器，在redis 6.0之后，将命令的转换使用了多线程，增加命令转换速度，在命令执行的时候，依然是单线程